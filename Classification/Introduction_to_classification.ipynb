{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae3bdbf3",
   "metadata": {},
   "source": [
    "# Whats is classification?\n",
    "\n",
    "Classification is a supervised machine learning technique used to categorize data into predefined classes or labels. It involves training a model on a labeled dataset, where the input features are associated with specific output labels. Once trained, the model can predict the class of new, unseen data based on the patterns it learned during training.\n",
    "\n",
    "For example, in email spam detection, a classification model can be trained to distinguish between \"spam\" and \"not spam\" emails based on features such as the presence of certain keywords, sender information, and email structure.\n",
    "\n",
    "There are various algorithms used for classification, including decision trees, support vector machines, logistic regression, and neural networks. The choice of algorithm depends on the nature of the data and the specific requirements of the task at hand.\n",
    "\n",
    "There are two types of learners in classification as lazy learners and eager learners."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf2cba5f",
   "metadata": {},
   "source": [
    "## 1 . Lazy Learners\n",
    "Lazy learners, also known as instance-based learners, do not build a general model during the training phase. Instead, they store the training data and wait until a query is made to make predictions. When a new instance needs to be classified, lazy learners compare it to the stored instances and use a similarity measure to determine the class.\n",
    "### Examples of Lazy Learners:\n",
    "- k-Nearest Neighbors (k-NN)\n",
    "- Case-Based Reasoning (CBR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f3a7df",
   "metadata": {},
   "source": [
    "## 2 . Eager Learners\n",
    "Eager learners, on the other hand, build a general model during the training phase. They analyze the training data and create a model that captures the underlying patterns and relationships. Once the model is built, it can be used to make predictions on new instances without needing to refer back to the original training data.\n",
    "### Examples of Eager Learners:\n",
    "- Decision Trees\n",
    "- Support Vector Machines (SVM)\n",
    "- Neural Networks\n",
    "- Logistic Regression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f009c721",
   "metadata": {},
   "source": [
    "# Classification algorithm\n",
    "\n",
    "There is a lot of classification algorithms available now but it is not possible to conclude which one is superior to other. It depends on the application and nature of available data set. For example, if the classes are linearly separable, the linear classifiers like Logistic regression, Fisher’s linear discriminant can outperform sophisticated models and vice versa."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e015cf",
   "metadata": {},
   "source": [
    "## 1. Decision Tree Classifier\n",
    "A decision tree is a classification or regression model that represents decision rules in a hierarchical tree structure. It relies on a set of mutually exclusive and exhaustive if-then rules, learned sequentially from the training data. After each rule is created, the instances covered by that rule are removed from further consideration. This process continues until a stopping criterion is satisfied.\n",
    "\n",
    "The tree is built using a top-down, recursive, divide-and-conquer strategy. All attributes should ideally be categorical; if they are continuous, they must be discretized beforehand. Attributes selected near the root have the greatest influence on the classification outcome, and they are chosen according to measures of impurity reduction such as information gain.\n",
    "\n",
    "However, decision trees are prone to overfitting, often producing overly complex trees that capture noise or outliers in the training data. Such overfitted models perform well on the training set but generalize poorly to unseen data. Overfitting can be controlled either through pre-pruning (stopping the growth of the tree early) or post-pruning (trimming branches after the tree is fully grown).\n",
    "\n",
    "![Decision Tree](images/decision_tree.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c04bc9",
   "metadata": {},
   "source": [
    "## 2. Naives Bayes Classifier\n",
    "\n",
    "Naive Bayes is a probabilistic classifier based on Bayes' theorem, which assumes that\n",
    "the features are conditionally independent given the class label. Despite this \"naive\" assumption, Naive Bayes classifiers often perform well in practice, especially for text classification tasks such as spam detection and sentiment analysis.\n",
    "The classifier calculates the posterior probability of each class given the input features and assigns the class with the highest probability to the instance. The formula used is:\n",
    " $$\n",
    "\\hat{y} = \\arg\\max_{c \\in \\mathcal{C}} P(C = c)\\prod_{i=1}^{d} P(X_i = x_i \\mid C = c)\n",
    "$$\n",
    "\n",
    "![Naives Bayes](images/Naives-Bayes.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eafb112f",
   "metadata": {},
   "source": [
    "## 3. Artificial Neural Networks (ANN)\n",
    "Artificial Neural Networks (ANNs) are computational models inspired by the structure and function of biological neural networks. They consist of interconnected nodes (neurons) organized in layers: an input layer, one or more hidden layers, and an output layer. Each connection between neurons has an associated weight that is adjusted during the training process to minimize the error in predictions. ANNs are capable of learning complex patterns and relationships in data, making them suitable for a wide range of tasks, including classification, regression, and pattern recognition.\n",
    "\n",
    "![Artificial Neural Networks](images/ANN.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94785e2d",
   "metadata": {},
   "source": [
    "## 4. K-Nearest Neighbors (KNN)\n",
    "K-Nearest Neighbors (KNN) is a simple, instance-based learning algorithm used for classification and regression tasks. In KNN, the class of a new instance is determined by the majority class of its 'k' nearest neighbors in the feature space. The distance between instances is typically measured using metrics such as Euclidean distance or Manhattan distance. KNN is a lazy learner, meaning it does not build a model during training but instead stores the training data for use during prediction. The choice of 'k' and the distance metric can significantly impact the performance of the algorithm.\n",
    "\n",
    "![K-Nearest Neighbors](images/KNN-2.png)\n",
    "\n",
    "Depending on the value of 'k', KNN can be sensitive to noise in the data. A small 'k' may lead to overfitting, while a large 'k' may smooth out important patterns. Therefore, selecting an appropriate value for 'k' is crucial for optimal performance.\n",
    "\n",
    "Distance Metrics:\n",
    "- Euclidean Distance\n",
    "    formula:\n",
    "$$\n",
    "d(p, q) = \\sqrt{\\sum_{i=1}^{n} (p_i - q_i)^2}\n",
    "$$\n",
    "\n",
    "- Manhattan Distance\n",
    "    formula:\n",
    "$$\n",
    "d(p, q) = \\sum_{i=1}^{n} |p_i - q_i|\n",
    "$$\n",
    "\n",
    "- Minkowski Distance\n",
    "    formula:  \n",
    "$$\n",
    "d(p, q) = \\left( \\sum_{i=1}^{n} |p_i - q_i|^m \\right)^{1/m}\n",
    "$$\n",
    "- Hamming Distance\n",
    "    formula:\n",
    "$$\n",
    "d(p, q) = \\sum_{i=1}^{n} \\delta(p_i, q_i)\n",
    "$$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c175bf0a",
   "metadata": {},
   "source": [
    "# Evaluation Metrics for Classification\n",
    "\n",
    "After training a classification model, it is essential to evaluate its performance to understand how well it generalizes to unseen data. Several metrics are commonly used to assess the effectiveness of a classifier:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec82e6e3",
   "metadata": {},
   "source": [
    "\n",
    "1. **Accuracy**: The proportion of correctly classified instances out of the total instances. It is calculated as:\n",
    "   $$\n",
    "   \\text{Accuracy} = \\frac{TP + TN}{TP + TN + FP + FN}\n",
    "   $$\n",
    "   where TP is true positives, TN is true negatives, FP is false positives, and FN is false negatives.\n",
    "\n",
    "2. **Precision**: The proportion of true positive predictions out of all positive predictions made by the classifier. It is calculated as:\n",
    "   $$\n",
    "    \\text{Precision} = \\frac{TP}{TP + FP}\n",
    "    $$\n",
    "3. **Recall (Sensitivity)**: The proportion of true positive predictions out of all actual positive instances. It is calculated as:\n",
    "   $$\n",
    "    \\text{Recall} = \\frac{TP}{TP + FN}\n",
    "    $$\n",
    "4. **F1 Score**: The harmonic mean of precision and recall, providing a single metric that balances both. It is calculated as:\n",
    "   $$\n",
    "    \\text{F1 Score} = 2 \\times \\frac{\\text{Precision} \\times \\text{Recall}}{\\text{Precision} + \\text{Recall}}\n",
    "    $$\n",
    "5. **Confusion Matrix**: A table that summarizes the performance of a classifier by displaying the counts of true positive, true negative, false positive, and false negative predictions.\n",
    "    |               | Predicted Positive | Predicted Negative |\n",
    "    |---------------|--------------------|--------------------|\n",
    "    | Actual Positive | TP                 | FN                 |\n",
    "    | Actual Negative | FP                 | TN                 |\n",
    "These metrics provide insights into different aspects of a classifier's performance, allowing for a comprehensive evaluation and comparison of different models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4818fda2",
   "metadata": {},
   "source": [
    "1. **Accuracy**: The proportion of correctly classified instances out of the total instances. It is calculated as:\n",
    "   $$\n",
    "   \\text{Accuracy} = \\frac{TP + TN}{TP + TN + FP + FN}\n",
    "   $$\n",
    "   where TP is true positives, TN is true negatives, FP is false positives, and FN is false negatives."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a97050a",
   "metadata": {},
   "source": [
    "2. **Precision**: The proportion of true positive predictions out of all positive predictions made by the classifier. It is calculated as:\n",
    "   $$\n",
    "    \\text{Precision} = \\frac{TP}{TP + FP}\n",
    "    $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae360f97",
   "metadata": {},
   "source": [
    "3. **Recall (Sensitivity)**: The proportion of true positive predictions out of all actual positive instances. It is calculated as:\n",
    "   $$\n",
    "    \\text{Recall} = \\frac{TP}{TP + FN}\n",
    "    $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49117f74",
   "metadata": {},
   "source": [
    "4. **F1 Score**: The harmonic mean of precision and recall, providing a single metric that balances both. It is calculated as:\n",
    "   $$\n",
    "    \\text{F1 Score} = 2 \\times \\frac{\\text{Precision} \\times \\text{Recall}}{\\text{Precision} + \\text{Recall}}\n",
    "    $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67daa04b",
   "metadata": {},
   "source": [
    "## Holdout Method\n",
    "\n",
    "One of the most common techniques for evaluating a model is the holdout method. In this approach, the dataset is split into two separate subsets: a training set and a test set, typically in an 80%-20% ratio.\n",
    "\n",
    "- The training set (80%) is used to train the model.\n",
    "\n",
    "- The test set (20%) contains unseen data and is used to assess the model’s predictive performance.\n",
    "\n",
    "This method provides a straightforward way to estimate how well a model generalizes to new data, though its results can vary depending on how the split is done."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15da1261",
   "metadata": {},
   "source": [
    "## Cross-validation\n",
    "\n",
    "Cross-validation is a robust technique for evaluating the performance of a machine learning model. It involves partitioning the dataset into 'k' subsets or folds. The model is trained on 'k-1' folds and tested on the remaining fold. This process is repeated 'k' times, with each fold serving as the test set once. The final performance metric is obtained by averaging the results from all 'k' iterations.\n",
    "Common types of cross-validation include:\n",
    "- **k-Fold Cross-Validation**: The dataset is divided into 'k' equal-sized folds. Each fold is used as a test set once, while the remaining 'k-1' folds are used for training.\n",
    "\n",
    "![Cross Validation](images/Cross-validation.png)\n",
    "\n",
    "Overfitting is a common issue in machine learning, where a model performs very well on training data but poorly on unseen data. k-Fold Cross-Validation is a technique used to detect and prevent overfitting.\n",
    "\n",
    "In this method, the dataset is randomly divided into k mutually exclusive subsets (folds) of approximately equal size. The procedure is as follows:\n",
    "\n",
    "One fold is kept aside as the test set, and the remaining k-1 folds are used to train the model.\n",
    "\n",
    "The model is evaluated on the test fold.\n",
    "\n",
    "This process is repeated k times, each time with a different fold used as the test set.\n",
    "\n",
    "The final performance metric is obtained by averaging the results over all k iterations, providing a more reliable estimate of the model’s generalization ability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a8ca81c",
   "metadata": {},
   "source": [
    "## ROC curve (Receiver Operating Characteristics)\n",
    "\n",
    "The ROC curve is a graphical representation used to evaluate the performance of a binary classification model. It plots the True Positive Rate (TPR) against the False Positive Rate (FPR) at various threshold settings. The TPR, also known as sensitivity or recall, measures the proportion of actual positives correctly identified by the model, while the FPR measures the proportion of actual negatives incorrectly classified as positives.\n",
    "\n",
    "![ROC Curve](images/Roc.webp) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c326c7",
   "metadata": {},
   "source": [
    "Here is the confusion matrix:\n",
    "\n",
    "\n",
    "|                   | Predicted Positive | Predicted Negative |\n",
    "|-------------------|--------------------|--------------------|\n",
    "| **Actual Positive** | TP                 | FN                 |\n",
    "| **Actual Negative** | FP                 | TN                 |\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
